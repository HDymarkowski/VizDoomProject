{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ! installing stuff\n",
    "\n",
    "! pip install jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# PART 2 : Converting to a Gym Enviroment\n",
    "\n",
    "from sre_parse import State\n",
    "from vizdoom import *\n",
    "from gym import Env # Import envoriment base class from OpenAI Gym\n",
    "from gym.spaces import Discrete, Box # Import gym spaces\n",
    "import cv2 # Import opencv to greyscale stuff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Imports for part 3\n",
    "import torch # pyTorch\n",
    "import os # for file navigation\n",
    "from stable_baselines3.common.callbacks import BaseCallback # import callback class from stablebaselines 3\n",
    "from stable_baselines3.common import env_checker # For checking if enviroment is in correct format\n",
    "import stable_baselines3\n",
    "\n",
    "# Imports for Part 4\n",
    "from stable_baselines3 import PPO # Import PPO for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VizDOOM OpenAI Gym Enviroment\n",
    "class VizDoomGym(Env):\n",
    "\n",
    "    def __init__(self, render = False):\n",
    "\n",
    "\n",
    "        super().__init__() # Inherit from \"Env\" class ???\n",
    "        # TODO: Learn more about OpenAI Gym\n",
    "\n",
    "        # Set up game\n",
    "        self.game = vizdoom.DoomGame() # TODO: IDK if \"vizdoom.\" does anything\n",
    "        self.game.load_config('ViZDoom/scenarios/basic.cfg')\n",
    "\n",
    "       # Render frame logic\n",
    "       # Rendering takes a lot of computing and we don't always want to see shit cause we don't care\n",
    "        if(render == False):\n",
    "            self.game.set_window_visible(False) # Don't pop up that window - we don't want to see it\n",
    "        else:\n",
    "            self.game.set_window_visible(True) # Show us the window\n",
    "\n",
    "        # Start game after we know whether to render or not\n",
    "        self.game.init()\n",
    "\n",
    "        # Set up action space and observation space\n",
    "        # TODO: I don't really get what these are\n",
    "        self.observation_space = Box(low = 0, high = 255, shape = (100, 160, 1), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3) # 3 actions we can take\n",
    "\n",
    " \n",
    "\n",
    "    def step(self, action): # How we take a step in the enviroment\n",
    "\n",
    "        # Specify action and take step\n",
    "        actions = np.identity(3) # 3 actions, represented as [1,0,0], [0,1,0], [0,0,1]\n",
    "        reward = self.game.make_action(actions[action], 4) # Make the action adn get the reward, 4 = frameskip parameter\n",
    "\n",
    "        # Get other stuff we need to return\n",
    "        if (self.game.get_state()):\n",
    "            state = self.game.get_state().screen_buffer # The next frame of the game\n",
    "            state = self.greyscale(state) # Does the grayscaling and resizing of the image, implemented in greyscale() method\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = ammo \n",
    "        else: # This logic in case we are finished and there is no next frame - would throw an error otherwise\n",
    "            # Just returns zeroes for shit\n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0\n",
    "\n",
    "        info = {\"info\":info}\n",
    "\n",
    "        done = self.game.is_episode_finished() # Whether or not the thing is finished\n",
    "\n",
    "        return state, reward, done, info\n",
    "\n",
    "    def render(): # Predifined in Vizdoom but needed to be openAI superclass or smth\n",
    "        pass\n",
    "\n",
    "    def reset(self): # What happens when we start a new game\n",
    "        self.game.new_episode() # Make a new game\n",
    "        state = self.game.get_state().screen_buffer # Next frame\n",
    "\n",
    "        return self.greyscale(state) # Return next frame, greyscaled\n",
    "\n",
    "    def greyscale(self, observation): # Greyscale and resize the game frame, get rid of the bottom bit too\n",
    "        # Applied in step() and reset()\n",
    "        # Gets rid of color channel i.e. the 3\n",
    "        # TODO: Maybe figure out how this works\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY) # Making shit gray - idk how this works\n",
    "\n",
    "        # Compresses frame down ???\n",
    "        resize = cv2.resize(gray, (160, 100), interpolation = cv2.INTER_CUBIC) # Reiszes image and scales it down - so we have more pixels to process\n",
    "        state = np.reshape(resize, (100, 160, 1)) # \n",
    "\n",
    "        return state\n",
    "\n",
    "    def close(self): # Close down the game so it's not floating\n",
    "        self.game.close()\n",
    "\n",
    "# Enviroment is now set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTORIAL 3\n",
    "\n",
    "# Setup callback\n",
    "\n",
    "# Standard training and logging callback\n",
    "# Used for saving the model in case shit goes wrong\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose = 1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok = True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "# Directories for saving and logging shit\n",
    "CHECKPOINT_DIR = './train/train_basic' # Checkpoint directory for saving trained reinforcement learning models\n",
    "LOG_DIR = './logs/log_basic' # \n",
    "\n",
    "# Create instance of train and logging callback\n",
    "\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n",
    "# check_freq = 10000 means that after every 10000 steps of training our model we're going to save a version of those pyTorch weights for our reinforcement learning agent (can be re-loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# Tutorial 4 - Train the RL Model\n",
    "\n",
    "\n",
    "env = VizDoomGym(render = False)\n",
    "\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=2048)\n",
    "# CnnPolicy as we are sending in an image\n",
    "# env passed through\n",
    "# LOG_DIR used for logging\n",
    "# Verbose means thaat we're going to have info appearing as we train\n",
    "# learning_rate can be increased\n",
    "# n_steps defines batch size for model. 256 = 256 sets of observations, actiosn, log probabililties and values will be stored in the buffer for one iteration\n",
    "#   > for basic is 300 so we use 256 (don't use whole max for game, just below)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviroment checker\n",
    "\n",
    "env_checker.check_env(env) # Runs with no errors if env is all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.5     |\n",
      "|    ep_rew_mean     | -80.6    |\n",
      "| time/              |          |\n",
      "|    fps             | 52       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.7        |\n",
      "|    ep_rew_mean          | -83.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009231068 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 3.24e-05    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 912         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.00225     |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | -61.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 26          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013235582 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.7        |\n",
      "|    ep_rew_mean          | -56.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 24          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009155963 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | 1.34e-05    |\n",
      "|    value_loss           | 3.22e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.3        |\n",
      "|    ep_rew_mean          | -59.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012048867 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.64e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.000575   |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.8        |\n",
      "|    ep_rew_mean          | -51.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011635141 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    value_loss           | 3.62e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 22.7      |\n",
      "|    ep_rew_mean          | -25.6     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 20        |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 687       |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0379501 |\n",
      "|    clip_fraction        | 0.347     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0.545     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.33e+03  |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | 0.0101    |\n",
      "|    value_loss           | 3.24e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.1        |\n",
      "|    ep_rew_mean          | -33.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 811         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017641261 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.993      |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.00176     |\n",
      "|    value_loss           | 3.28e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.6        |\n",
      "|    ep_rew_mean          | 0.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013709828 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.966      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 922         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.00899     |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.1        |\n",
      "|    ep_rew_mean          | -25         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017840736 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.891      |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.8        |\n",
      "|    ep_rew_mean          | -46.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1177        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009150118 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.6        |\n",
      "|    ep_rew_mean          | -46.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1286        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056906514 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.0137      |\n",
      "|    value_loss           | 2.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 24.2         |\n",
      "|    ep_rew_mean          | -40.3        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1391         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136295855 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.691       |\n",
      "|    explained_variance   | 0.705        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | 0.00842      |\n",
      "|    value_loss           | 2.15e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.7        |\n",
      "|    ep_rew_mean          | -40.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1502        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010266973 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.8        |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 883         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 0.00659     |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.6        |\n",
      "|    ep_rew_mean          | -27.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 19          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1610        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031312704 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.0041      |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.8       |\n",
      "|    ep_rew_mean          | -4.61      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 18         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 1736       |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01184408 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.761     |\n",
      "|    explained_variance   | 0.84       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 728        |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | 0.00661    |\n",
      "|    value_loss           | 1.66e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.6        |\n",
      "|    ep_rew_mean          | -8.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1859        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016985362 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.00711     |\n",
      "|    value_loss           | 3.53e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.3        |\n",
      "|    ep_rew_mean          | -52.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1980        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012642308 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.00376     |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.7        |\n",
      "|    ep_rew_mean          | 18.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2104        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013089046 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 560         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00733     |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | -13.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2233        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012215594 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 397         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.00657     |\n",
      "|    value_loss           | 1.34e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.1        |\n",
      "|    ep_rew_mean          | 15.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2345        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013668121 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 902         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00455     |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 23        |\n",
      "|    ep_rew_mean          | -23.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 18        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 2461      |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0127622 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.516    |\n",
      "|    explained_variance   | 0.825     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 855       |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 0.00383   |\n",
      "|    value_loss           | 1.99e+03  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 21.8         |\n",
      "|    ep_rew_mean          | -19.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2589         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067676455 |\n",
      "|    clip_fraction        | 0.0955       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.45e+03     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | 0.0012       |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.2        |\n",
      "|    ep_rew_mean          | -9.49       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 18          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2710        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013241139 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.551      |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 554         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | 0.00735     |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 23.1         |\n",
      "|    ep_rew_mean          | -24.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 2835         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072646253 |\n",
      "|    clip_fraction        | 0.0987       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 426          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 0.00535      |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.8        |\n",
      "|    ep_rew_mean          | -2.65       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 2980        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014964552 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.1        |\n",
      "|    ep_rew_mean          | -17.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 3092        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009277154 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 703         |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.000196    |\n",
      "|    value_loss           | 1.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 21.8        |\n",
      "|    ep_rew_mean          | -18.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 3205        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011856579 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 730         |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.00627     |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.8        |\n",
      "|    ep_rew_mean          | 12.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 3331        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019748569 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 399         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.00258     |\n",
      "|    value_loss           | 1.03e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.9        |\n",
      "|    ep_rew_mean          | -8.38       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 3459        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014030684 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.436      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 597         |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.00089     |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.8        |\n",
      "|    ep_rew_mean          | -8.13       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 3585        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007951409 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 265         |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.00662     |\n",
      "|    value_loss           | 991         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 19.4       |\n",
      "|    ep_rew_mean          | -6.97      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 3700       |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01126756 |\n",
      "|    clip_fraction        | 0.0824     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.467     |\n",
      "|    explained_variance   | 0.826      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 839        |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | 0.00313    |\n",
      "|    value_loss           | 1.26e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 20.7       |\n",
      "|    ep_rew_mean          | -9.59      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 3808       |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08990529 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.476     |\n",
      "|    explained_variance   | 0.875      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 615        |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | 0.00539    |\n",
      "|    value_loss           | 936        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 21.8       |\n",
      "|    ep_rew_mean          | -14.6      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 3919       |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00777403 |\n",
      "|    clip_fraction        | 0.0769     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.313     |\n",
      "|    explained_variance   | 0.784      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 607        |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | 0.00476    |\n",
      "|    value_loss           | 1.53e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 19.2         |\n",
      "|    ep_rew_mean          | -2.22        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 17           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 4031         |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063381693 |\n",
      "|    clip_fraction        | 0.0692       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0.784        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 656          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | 0.00647      |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 16.4        |\n",
      "|    ep_rew_mean          | 13.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 4142        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010205036 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.4        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 628         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.0072      |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.8        |\n",
      "|    ep_rew_mean          | 3.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 4253        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009061056 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.4        |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 422         |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.00847     |\n",
      "|    value_loss           | 1.02e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.2       |\n",
      "|    ep_rew_mean          | 3.63       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 4363       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03350065 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.505     |\n",
      "|    explained_variance   | 0.82       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 711        |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00723   |\n",
      "|    value_loss           | 1.12e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 15        |\n",
      "|    ep_rew_mean          | 22        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 17        |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 4473      |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0130539 |\n",
      "|    clip_fraction        | 0.119     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.386    |\n",
      "|    explained_variance   | 0.831     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 931       |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | 0.00969   |\n",
      "|    value_loss           | 1.32e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.2        |\n",
      "|    ep_rew_mean          | 2.88        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 4582        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011581324 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 620         |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00191     |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 18.6       |\n",
      "|    ep_rew_mean          | 3.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 17         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 4711       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02195636 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.49      |\n",
      "|    explained_variance   | 0.848      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 871        |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.00327    |\n",
      "|    value_loss           | 1.23e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 18.9        |\n",
      "|    ep_rew_mean          | 2.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 4822        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024916176 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00551     |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.9        |\n",
      "|    ep_rew_mean          | -9.91       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 4931        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008635242 |\n",
      "|    clip_fraction        | 0.0948      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 822         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.0026      |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.4        |\n",
      "|    ep_rew_mean          | -0.77       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 5043        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015340663 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.338      |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 920         |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00184     |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Runs the PPO training model\n",
    "\n",
    "model.learn(total_timesteps=100000, callback=callback )\n",
    "\n",
    "# Get tensorboard graphs with (in ppo training folder) \"tensorboard --logrid=.\"\n",
    "# He explains tensorboard graphs at 1:42\n",
    "\n",
    "# Agent is now trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial 5 - Testing the Agent\n",
    "import time\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38\n"
     ]
    }
   ],
   "source": [
    "model.load('./train/train_basic/best_model_100000') # Reload model from disk\n",
    "##PPO.load() works too\n",
    "\n",
    "env = VizDoomGym(render = True)\n",
    "mean_reward, _ = evaluate_policy(model, env, n_eval_episodes = 100)\n",
    "# \"_\" is used when something you don't care about is returned\n",
    "# pass in model, enviroment and amount of episodes we want to evaluate the policy for\n",
    "\n",
    "print(mean_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ViZDoomIsNotRunningException",
     "evalue": "Controlled ViZDoom instance is not running or not ready.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mViZDoomIsNotRunningException\u001b[0m              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-543977f8f7dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 5 games\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# reset enviroment, store game frame in \"observations\" variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtotal_reward\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f588f84353c4>\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# What happens when we start a new game\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Make a new game\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreen_buffer\u001b[0m \u001b[1;31m# Next frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mViZDoomIsNotRunningException\u001b[0m: Controlled ViZDoom instance is not running or not ready."
     ]
    }
   ],
   "source": [
    "# This is a lot like what we did in the very beginning i.e. the initial tutorial\n",
    "\n",
    "for episode in range(5): # 5 games\n",
    "    obs = env.reset() # reset enviroment, store game frame in \"observations\" variable\n",
    "    done = False\n",
    "    total_reward= 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs) # model predicts what ation to take\n",
    "        obs, reward, done, info = env.step(action) # actually take the predicted action\n",
    "        time.sleep(0.25)\n",
    "        total_reward += reward\n",
    "    print(\"Total reward for episode {} is {}\".format(episode, total_reward))\n",
    "    time.sleep(2)\n",
    "    \n",
    "# 1:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial 6 - Change Levels\n",
    "\n",
    "# Look at defend_center notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

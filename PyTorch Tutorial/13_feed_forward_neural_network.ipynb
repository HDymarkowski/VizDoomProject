{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nToday, we will implement our first multi-layer neural network that can do digit classification based\\non the famous MNIST dataset\\n\\nWe will put all of the things from the last tutorials together:\\n    > MNIST Dataset\\n    > DataLoader, Transformation\\n    > Multilayer Neural Network (input layer, hidden layer, output layer), Activation functions\\n    > Loss and Optimizer\\n    > Training loop (batch training)\\n    > Model evaluation\\n    > GPU support\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTE: Deep learning is a machine learning technique that teaches computers to do what comes naturally \n",
    "to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them \n",
    "to recognize a stop sign, or to distinguish a pedestrian from a lamppost.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Today, we will implement our first multi-layer neural network that can do digit classification based\n",
    "on the famous MNIST dataset\n",
    "\n",
    "We will put all of the things from the last tutorials together:\n",
    "    > MNIST Dataset\n",
    "    > DataLoader, Transformation\n",
    "    > Multilayer Neural Network (input layer, hidden layer, output layer), Activation functions\n",
    "    > Loss and Optimizer\n",
    "    > Training loop (batch training)\n",
    "    > Model evaluation\n",
    "    > GPU support\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision # For datasets\n",
    "import torchvision.transforms as transforms # For transforms\n",
    "import matplotlib.pyplot as plt # To graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# cuda = gpu, cpu = cpu\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "input_size = 784 # The images are 28x28 which when flattened is 1x784\n",
    "hidden_size = 100 # ??? Can try out different sizes here\n",
    "num_classes = 10 # 10 classes - digits form 0 to 9\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(6):\\n    plt.subplot (2, 3, i + 1) # 2 rows, 3 columns, index = i + 1\\n    plt.imshow(samples[i])\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import MNIST dataset\n",
    "\n",
    "# Dataset for training\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data', \n",
    "                                           train = True,\n",
    "                                           transform = transforms.ToTensor(),\n",
    "                                           download = True)\n",
    "# root for root folder\n",
    "# train = True means it is a training dataset\n",
    "# transform ToTensor makes the data a tensor\n",
    "# download = True means it should be downloaded if it is not already\n",
    "\n",
    "# Dataset for testing\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data', \n",
    "                                           train = False,\n",
    "                                           transform = transforms.ToTensor())\n",
    "# Notice, train = False and no download needed\n",
    "\n",
    "\n",
    "# Data loaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle = True)\n",
    "# shuffle = True shuffles the data around - good for testing\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle = False)\n",
    "# Shuffle does not matter for the evaluation\n",
    "\n",
    "# Check if it all works\n",
    "# I can't get iter to work\n",
    "\n",
    "# Samples output is [100, 1, 28, 28]\n",
    "# First one because 100 samples in our batch\n",
    "# No color channels so next one is just 1\n",
    "# Next 2 are image i.e. 28 x 28\n",
    "\n",
    "# Labels is just a size 100 tensor (just 100 labels for which number it is)\n",
    "\n",
    "\n",
    "# Plot it\n",
    "\"\"\"\n",
    "for i in range(6):\n",
    "    plt.subplot (2, 3, i + 1) # 2 rows, 3 columns, index = i + 1\n",
    "    plt.imshow(samples[i])\n",
    "\"\"\"\n",
    "\n",
    "# The above shows images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We now want to classify these images (hadnwritten numbers as digits 0-9), we will set up a fully\n",
    "connected neural network with one hidden layer\n",
    "\"\"\"\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        # Needs to have input size, hidden size and ouput size (which is the number of classes)\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        # Create our layers\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) # nn.Linear(inputsize, outputsize)\n",
    "        self.relu = nn.ReLU() # ReLu activation function\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        \n",
    "        # We don't apply softmax because this is a multi-class problem\n",
    "        # We will use cross-entropy loss (kinda applies softmax for us)\n",
    "        # Instead, we just return \"out\"\n",
    "        \n",
    "        return out\n",
    "        \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Loss and optimizer\n",
    "\n",
    "# Loss funciton\n",
    "criterion = nn.CrossEntropyLoss() # Applies softmax for us so we don't put it in the model\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # What is this optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1/2, step100/600, loss = 0.2782\n",
      "epoch1/2, step200/600, loss = 0.2487\n",
      "epoch1/2, step300/600, loss = 0.1877\n",
      "epoch1/2, step400/600, loss = 0.2146\n",
      "epoch1/2, step500/600, loss = 0.1574\n",
      "epoch1/2, step600/600, loss = 0.2355\n",
      "epoch2/2, step100/600, loss = 0.3102\n",
      "epoch2/2, step200/600, loss = 0.1732\n",
      "epoch2/2, step300/600, loss = 0.2400\n",
      "epoch2/2, step400/600, loss = 0.1188\n",
      "epoch2/2, step500/600, loss = 0.1559\n",
      "epoch2/2, step600/600, loss = 0.2153\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0 # Running correct predictions\n",
    "\n",
    "# First, loop over epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Next, loop over batches\n",
    "    for i, (images, labels) in enumerate(train_loader): # enumerate gives us the inedex\n",
    "        ## We have to reshae our images first\n",
    "        # Shape is currently 100 x 1 x 28 x 28\n",
    "        # But our input size is (28 * 28=) 784\n",
    "        # So our image tensor needs shape 100 x 784 (n_bacthes x image_size)\n",
    "        images = images.reshape(-1, 28*28).to(device) # -1 is found out automatically for us\n",
    "        labels = labels.to(device)\n",
    "        # .to(device) pushes it to gpu if possible\n",
    "        \n",
    "        ## Forward pass\n",
    "        outputs = model(images)\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        ## Backwards pass\n",
    "        # First, empty values in gradient attribute\n",
    "        optimizer.zero_grad()\n",
    "        # Do backward propogation\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## Print loss\n",
    "        \n",
    "        # Tensorboard\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if ((i+1) % 100 == 0): # Every 100th statement\n",
    "            print(f'epoch{epoch+1}/{num_epochs}, step{i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "            \n",
    "            writer.add_scalar('training_loss', running_loss/100, epoch * n_total_steps + i) # Last one is current global step\n",
    "            writer.add_scalar('accuracy', running_correct/100, epoch * n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "\n",
    "# We don't want to comput the gradients\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    # Loop over all batches in test samples\n",
    "    for images, labels in test_loader:\n",
    "        # Reshape this as we did above\n",
    "        images = images.reshape(-1, 28*28).to(device) # -1 is found out automatically for us\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Calculate predictions\n",
    "        outputs = model(images) # model() is trained now and is given test images\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # torch.max returns value, index (index = class label)\n",
    "        n_samples += labels.shape[0] # Gives us number of samples in current batch (should be 100)\n",
    "        n_correct += (predictions == labels).sum().item() # Fancy way of doing \"for each prediction\n",
    "        # ... if it is right add 1 to n_corrrect\n",
    "        \n",
    "    # Total accuracy\n",
    "    accuracy = 100 * (n_correct/n_samples)\n",
    "    print(f'accuracy = {accuracy}') # 95.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Important part I keep forgetting\n",
    "\n",
    "for epoch in range(num_epochs): (1)\n",
    "    for i, (images, labels) in enumerate(train_loader): (2)\n",
    "    \n",
    "(1) loops over the EPOCHS (how many times we are training over the data)\n",
    "(2) loops over the batches of each epoch (like the parts of each epoch)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 - Tensorboard\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/mnist') # Set up writer\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "# For showing images\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "\n",
    "# Go into VizDoomProject and do \"tensorboard --logdir=runs\"\n",
    "\n",
    "\n",
    "# For graph\n",
    "                                       \n",
    "writer.add_graph(model, example_data.reshape(-1, 28*28))\n",
    "writer.close()\n",
    "\n",
    "\n",
    "# For metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
